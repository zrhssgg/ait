# AI For U 人人皆可Ai

# 免费版一键安装脚本

【获取[强化版一键安装脚本](https://gf.bilibili.com/item/detail/1107198073)】【[强化版视频教程](https://www.bilibili.com/video/BV13UBRYVEmX/)】

在 AI 创作领域，显卡及工具的配置往往会成为入门的第一道门槛。本视频就来解决这两个痛点，让人人都有你的AI PC,让你都能轻松部署。

1. 一张显卡 ：硬件上满足你，达到人人都有AI PC
2. ComfyUI 安装： 软件上满足你，达到人人都能部署
3. ComfyUI 使用：下载模型，一键运行，达到人人都能使用

## 支持平台
- [x] 腾讯 Cloud Studio 【免费T4 16G显存】【[视频介绍](https://www.bilibili.com/video/BV1BJmSYFE2a/)】
- [] Google Colab
- [] Kaggle
- [] 启智免费算力平台 【免费A100 40G显存】【[视频介绍](https://www.bilibili.com/video/BV1an4y1X7h5/)】


## 快速开始【免费版】
### 只 ComfyUI 的安装示范
### 包含 ComfyUI + ComfyUI Manager + Ngrok + 国内环境可安装

1. **克隆仓库**：
    只需运行命令：
    ```bash
    git clone https://github.com/aigem/aitools.git
    ```
    国内环境可用：
    ```bash
    git clone https://openi.pcl.ac.cn/niubi/aitools.git
    ```
    ```bash
    git clone https://gitee.com/fuliai/aitools.git
    ```

    ```bash
    cd aitools && git pull
    ```
    

2. **运行安装脚本**：
    ```bash
    bash aitools.sh
    ```
    在菜单中选择选项 1 (ComfyUI) 开始自动安装

3. **程序运行说明**： 

    - 启动ComfyUI服务
    `cd /workspace/ComfyUI/ && python main.py`

    - 启动 Ngrok 隧道服务
    新开一个终端(命令行)运行 Ngrok 隧道服务
     `ngrok http 8188` 

    - 访问 Ngrok 隧道服务生成的网址

# 强化版一键安装脚本 

## 说说ComfyUI 一键安装脚本 【获取[强化版一键安装脚本](https://gf.bilibili.com/item/detail/1107198073)】【[强化版视频教程](https://www.bilibili.com/video/BV13UBRYVEmX/)】
ComfyUI 一键安装工具致力于提供更便捷的部署体验。以下是我们的优势： 
 
### 1. 极致的安装体验
- 🚀 **一键式部署**：告别繁琐配置，**一键完成从环境准备到服务启动**的全流程
- 🔄 **智能依赖处理**：自动解决复杂的包依赖关系，避免版本冲突
- 🎉 **模块化设计**：各功能模块独立，便于维护和扩展

### 2. 国内环境深度优化
- 🚅 **高速镜像源**：**Github源的国内替代**
- 📦 **稳定下载**：支持大文件断点续传，模型下载更稳定
- ⚖️ **多方式下载**：提供**3种下载方式**，**国内网络**可用。支持HuggingFace、modelscope的模型下载，支持**aria2下载**，支持断点续传

### 3. 功能增强
- 🔌 **即插即用**：内置**ComfyUI Manager**，扩展管理更轻松
- 📚 **丰富资源**：优质模型与插件一键下载，开箱即用
- 🛠️ **扩展性强**：支持自定义扩展，满足个性化需求
- 🎉 **一键运行**：真的一键到底，**一行命令下载**模型，**一行命令启动并运行**

### 4. 全平台兼容支持 
- ☁️ **云端优化**：完美适配**良心云Cloud Studio**免费算力平台
- 💻 **硬件适配**：支持 NVIDIA GPU 环境
- 🖥️ **系统兼容**：计划支持**更多免费算力**平台

### 5. 持续更新与维护
- 🆕 **版本同步**：同步 ComfyUI 更新
- 📈 **定期更新**：持续优化模型与插件，提升使用体验

### 6. 版本管理与兼容性
- 🎯 **版本更新**：自动安装 CUDA 与 PyTorch 新版本

### 7. 便捷的配置管理
- ⚙️ **集中配置**：统一管理所有**配置项**，一目了然
- 💻 **开机进入特定虚拟环境**：开机自动进入**ComfyUI特定虚拟环境**，无需手动切换

## 如何用ComfyUI 一键安装脚本 [【视频教程】](https://www.bilibili.com/video/BV13UBRYVEmX/)

- 在[此链接]https://gf.bilibili.com/item/detail/1107198073)获取一键安装脚本
- [登录良心云Cloud Studio: https://ide.cloud.tencent.com/](https://ide.cloud.tencent.com/)
- 新建一个高性能空间，这里我们选择 **Llama3.2 - RAG SFT练习** 这个模板
- 进入空间，将所有获取到的脚本文件上传到我们新建的空间
- 在命令行中运行一键安装脚本：`bash startup.sh`
- 来到安装界面，选择安装选项：ComfyUI,输入 1 回车
- 等待脚本运行完成，安装的最后，会提示输入Ngrok Token，输入后回车
- 到ngrok官网注册一个账号，在linux项中获取我们的Ngrok Token
- 之后会自动运行ComfyUI服务，并生成一个访问地址
- 打开浏览器，访问生成的访问地址，开始使用

## 如何使用ComfyUI [【视频教程】](https://www.bilibili.com/video/BV13UBRYVEmX/)
- 下载模型：
    1. 下载modelscope(https://www.modelscope.cn/models)模型：`bash scripts/download.sh`
    先获取要下载模型的相关信息，然后运行脚本：比如 
    2. 下载huggingface(https://huggingface.co/models)模型：`bash scripts/download.sh`
    先获取要下载模型的相关信息，然后运行脚本：比如 
    3. 【主要使用】aria2下载：请在一键包内说明文件中查看
    - 记得将 hf-mirror.com 替换了 huggingface.co
    - 大家查看 huggingface 模型可以使用 https://hf-mirror.com/models

- 一键运行ComfyUI及Ngrok：
    在命令行中运行：
    `bash scripts/run.sh`

- 使用模型：
    附赠视频中的workflow文件，是关于Flux redux 最简工作流，使用方法：
    1. 这个workflow文件是基于Flex.1 dev及最新flux Redux的
    2. 使用方法：
    确保有以下模型文件，下载可使用一键包内说明文件的命令进行下载：
    - `models/checkpoints/flux_redux.safetensors`
    - `models/vae/vae_approx-sdxl_v3.safetensors`
    - `models/clip_vision/sigclip_vision_patch14_384.safetensors`
    - `models/style_models/flux1-redux-dev.safetensors`

【[强化版视频教程](https://www.bilibili.com/video/BV13UBRYVEmX/)】
【获取[强化版一键安装脚本](https://gf.bilibili.com/item/detail/1107198073)】

